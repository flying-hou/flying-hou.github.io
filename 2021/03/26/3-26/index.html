<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="htx">
  <meta name="keywords" content="">
  <title>阅读笔记（3.26) - htx&#39;s blog</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>


  <style>
    html {
      filter: grayscale(100%);
    }
  </style>

<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>htx's blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="https://pan.htx1998.cn" target="_blank" rel="noopener">
                <i class="iconfont icon-briefcase"></i>
                云盘
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('https://tva1.sinaimg.cn/large/e6c9d24ely1h4lsdsd3a2j21900u0gqf.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2021-03-26 10:00">
      2021年3月26日 上午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      32
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p class="note note-info">
                
                  本文最后更新于：2021年4月14日 晚上
                
              </p>
            
            <article class="markdown-body">
              <ul>
<li><h2 id="论文阅读方面："><a href="#论文阅读方面：" class="headerlink" title="论文阅读方面："></a>论文阅读方面：</h2></li>
</ul>
<p>[1] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[J]. arXiv preprint arXiv:1706.03762, 2017.</p>
<p>[2] Han L, Wang P, Yin Z, et al. Exploiting Better Feature Aggregation for Video Object Detection[C]//Proceedings of the 28th ACM International Conference on Multimedia. 2020: 1469-1477.</p>
<p>[3] Chen Q, Wang Y, Yang T, et al. You Only Look One-level Feature[J]. arXiv preprint arXiv:2103.09460, 2021.</p>
<p>[4] Chefer H, Gur S, Wolf L. Transformer Interpretability Beyond Attention Visualization[J]. arXiv preprint arXiv:2012.09838, 2020.</p>
<ul>
<li><h2 id="代码运行方面："><a href="#代码运行方面：" class="headerlink" title="代码运行方面："></a>代码运行方面：</h2></li>
</ul>
<p>本周对香港中文大学mmlab开源的SELSA代码进行了环境配置、初步运行测试。在不调整原始参数的情况下，其mAP可以达到82%，比原始论文中报告的80.25%高出不少。</p>
<p>下一步计划认真研读这份代码，在其基础上进行改进。</p>
<p><img src="https://i.loli.net/2021/03/26/fR5PVpXK9eqrkds.png" srcset="/img/loading.gif" alt="image-20210326165354768"></p>
<h1 id="1-Attention-is-all-you-need"><a href="#1-Attention-is-all-you-need" class="headerlink" title="1.Attention is all you need"></a>1.Attention is all you need</h1><ul>
<li><strong>这篇文章是目前很火的Transformer框架的开山之作，遂找来进行阅读。</strong></li>
</ul>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>主流的顺序翻译模型基于复杂的循环或卷积神经网络，其包含编码器和解码器。效果最好的模型通过注意力机制连接编码器和解码器。本文提出了一个新的简单的网络结构，Transformer，仅仅基于注意力机制，完全抛开循环和卷积。</p>
<p>递归模型通常沿着输入输出序列的符号位置进行因子计算。这种固有的顺序性排除了训练示例中的并行化，当序列长度变长时，并行化就变得至关重要，因为内存约束限制了示例之间的批处理。</p>
<p>本文提出的Transformer模型结构，避开了循环，完全依赖注意力机制来庙会输入和输出之间的全局依赖。</p>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>自注意力（内部注意力）是一个注意力机制，联系不同位置的单个序列，来计算序列的一个表示。自注意力已经在多种任务上成功应用，包括阅读理解，抽象总结等。</p>
<p>端到端的memory网络基于递归注意力机制，而不是序列对其的递归，并且已经被证明在简单语言问答和语言建模任务中表现良好。</p>
<p>Transformer是第一个完全依赖自注意力来计算输入和输出表示的转移模型，而无需使用序列对齐的RNN或卷积。</p>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>最有竞争力的神经序列转移模型具有一个编码-解码结构。这里的编码器将符号表示的输入序列(x1…xn)映射为连续表示的序列z=(z1,…zn)。给出z，解码器生成一个输出序列(y1,…ym)每次表示一个元素。在每一步模型是自动回归的。生成下一个时，将先前生成的符号用作附加输入。</p>
<p>Transformer遵循以上的整体结构，使用堆叠的self-attention和point-wise、编码器使用全连接层。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goqpsxfjuxj30le0uwdkv.jpg" srcset="/img/loading.gif" alt="image-20210320215803807" style="zoom:50%;" /></p>
<h3 id="3-1-编码器和解码器的堆叠"><a href="#3-1-编码器和解码器的堆叠" class="headerlink" title="3.1 编码器和解码器的堆叠"></a>3.1 编码器和解码器的堆叠</h3><h4 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h4><p>编码器由N=6个完全相同的层堆叠组成。每一层有两个子层。首先是一个multi-head 自注意力机制，其次是一个简单的position-wise的全连接前向传播网络。在这两个子层中采用了残差连接、层正规化。每个子层的输出是</p>
<p><script type="math/tex">LayerNorm(x+Sublayer(x))</script>,其中$Sublayer(x)$是sub-layer自身的函数。为了促进残差连接，模型中所有的子层和嵌入层的输出维度都是512维。</p>
<h4 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h4><p>解码器也由N=6个完全相同的层堆叠而成。除了每个编码器层中的两个子层之外，解码器插入了第三个子层，该第三个子层在编码器堆栈的输出上执行multi-head attention。与编码器相同，解码器也在每个子层中采用了残差连接、层正规化。作者也修改了解码器堆栈中的self-attention子层，以防止器出现在后续的位置。这种掩盖，以及输出嵌入被一个位置偏移的事实，确保了对位置i的预测只能依赖于小于i位置的已知输出。</p>
<h3 id="3-2-Attention"><a href="#3-2-Attention" class="headerlink" title="3.2 Attention"></a>3.2 Attention</h3><p>注意力函数可以描述为将查询和一组键值对映射到输出，其中查询、键、值和输出都是向量。将输出计算为值的加权和，其中分配给每个值的权重是通过查询与相应键的兼容性函数来计算的。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goqpta37gwj30xy0k2tcf.jpg" srcset="/img/loading.gif" alt="image-20210320215823909" style="zoom: 33%;" /></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>和大多数seq2seq模型一样，transformer的结构也是由encoder和decoder组成。</p>
<p>编码器的输入句子首先会经过一个自注意力层，可以帮助编码器再对每个单词编码时关注输入句子的其他单词。</p>
<p>自注意力层的输出会传递到前馈神经网络中，每个位置单词对应的前馈神经网络都完全一样。</p>
<p>解码器中也有编码器的自注意力层和前馈层。此外，这两个层之间还有一个注意力层，用来关注输入句子的相关部分。</p>
<h1 id="2-Exploiting-Better-Feature-Aggregation-for-Video-Object-Detection"><a href="#2-Exploiting-Better-Feature-Aggregation-for-Video-Object-Detection" class="headerlink" title="2.Exploiting Better Feature Aggregation for Video Object Detection"></a>2.Exploiting Better Feature Aggregation for Video Object Detection</h1><ul>
<li><strong>这篇文章是目前视频目标检测论文中报告精度最高的一篇，mAP达到84.8%。</strong></li>
</ul>
<h4 id="作者指出了当前基于关系的特征聚合方法存在的三个问题："><a href="#作者指出了当前基于关系的特征聚合方法存在的三个问题：" class="headerlink" title="作者指出了当前基于关系的特征聚合方法存在的三个问题："></a>作者指出了当前基于关系的特征聚合方法存在的三个问题：</h4><ol>
<li>只考虑目标间的时间依赖，忽略了空间关系</li>
<li>这些方法在时间阈上直接聚合支持帧所有的proposal，不考虑其是否属于同一类。使得其不可避免的从不相关的类中带来有缺陷的proposals。</li>
<li>其直接聚合支持proposal和目标proposal的特征，没有进行特征对齐。为后续的分类和回归带来了没有经过对齐的特征。</li>
</ol>
<h4 id="基于以上问题，本文提出了以下创新："><a href="#基于以上问题，本文提出了以下创新：" class="headerlink" title="基于以上问题，本文提出了以下创新："></a>基于以上问题，本文提出了以下创新：</h4><ul>
<li>提出Class-constrained spatial-temporal relation network<ul>
<li>操作目标region proposals，学习两种关系：<ul>
<li>从辅助帧采样的相同类的region proposal依赖</li>
<li>目标帧不同目标proposal之间的空间关系</li>
</ul>
</li>
<li>首次同时编码时域和空域的信息。</li>
</ul>
</li>
<li>提出Correlation-based feature alignment module，更好的在时域进行特征聚合。</li>
<li>提出了一个基于相关的特征对齐方法，在时域上对齐支持帧和目标帧，以进行特征聚合。</li>
<li>提出class homogeneity constraint，将视频帧顺序打乱，通过在RPN后加入一个分类器，来实现仅用相同类的proposal来增强目标proposal，减少特征聚合中有缺陷的region proposals，并且滤除来自其他类的无效的信息，得到更精确的聚合特征。这样不仅大大减少了需要计算相关性的proposal的数量，并且是在一个统一的端到端的网络框架中，不需要后处理（隐含的嵌入了传统的后处理策略）。</li>
</ul>
<p><img src="https://i.loli.net/2021/03/23/aONPqehE5HnDFXr.png" srcset="/img/loading.gif" alt="image-20210323125757262" style="zoom:50%;" /></p>
<p>首先使用RPN获得每一帧的proposal。之后设计一个简单的分类器来预测每个proposal的类名。之后使用<strong>时间聚合模块（TAM）</strong>用支持帧的同类proposal特征来增强目标proposal特征。特征对齐模块（TA）被插入到时间聚合模块中，以进行更好地特征聚合。最终，使用空间关系模块（SRM），分析相同帧目标的交互，来对目标的拓补关系建模，进一步使用相同帧的proposal来增强目标proposal的特征。</p>
<h3 id="所提出的模块："><a href="#所提出的模块：" class="headerlink" title="所提出的模块："></a>所提出的模块：</h3><p><strong>TAM模块：</strong>用于将辅助帧的同类proposal特征来增强目标proposal，其中采用Transformer机制来选出可用于特征聚合的最具信息量的辅助proposal。通过cos相似性计算出目标proposal和辅助proposal的表观相似性。之后使用计算出的相似性对特征进行加权和。最后<strong>使用Liner Projection，重新将原始的表观特征包含在内。</strong></p>
<p><strong>SRM模块：</strong>挖掘<strong>目标帧</strong>中proposal之间的空间位置关系，计算出几何相似性。最终的相似性又包含了上一步计算出的表观相似性。</p>
<p><strong>特征对齐模块</strong>：通过利用标准差和均值，计算出支持proposal（x,y)位置和目标proposal（m,n)位置的相关性（其中包含了1x1的卷积、对目标proposal的（m,n)位置进行复制、用提出的公式执行“相关”操作）。最终根据计算出的相关性权重，对支持proposal特征图进行加权和，就可以得到其在目标proposal(m,n)位置的对齐过的特征。</p>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>作者提出了一个class-constrained时空关系网络和一基于相关的特征对齐模块。前者同时考虑了不同帧相同类的时间依赖性、以及同一帧不同目标的空间拓补关系。此外，作者将辅助帧打乱（随机采样），利用了整个视频的目标信息，相比传统的后处理方法更有效。</p>
<h1 id="3-You-Only-Look-One-level-Feature"><a href="#3-You-Only-Look-One-level-Feature" class="headerlink" title="3. You Only Look One-level Feature"></a>3. You Only Look One-level Feature</h1><p>本文指出FPN（特征金字塔网络）的成功之处在于其“分而治之”的解决思路而非多尺度特征融合。作者从优化的角度出发，仅使用一级特征进行检测，提出了YOLOF(You Only Look One-level Feature)。YOLOF有两个关键性模块：Dilated Encoder与Uniform Matching。</p>
<h3 id="YOLOF框架"><a href="#YOLOF框架" class="headerlink" title="YOLOF框架"></a>YOLOF框架</h3><p><img src="https://i.loli.net/2021/03/25/CU7IY6QEJjmqOeD.png" srcset="/img/loading.gif" alt="image-20210325190606151" style="zoom: 50%;" /></p>
<ul>
<li>BackBone。在所有模型中，作者简单的采用了ResNet与ResNeXt作为骨干网络，所有模型在ImageNet上训练，输出C5特征该通道数为2048，下采样倍率为32；</li>
<li>Encoder。作者参考FPN添加了两个投影层，将通道数降到512，并堆叠四个不同扩张因子的残差模块；</li>
<li>Decoder。在这部分，作者采用了RetinaNet的主要设计思路，它包含两个并行的任务相关的Head分别用于分类和回归。作者仅仅添加两个微小改动：(1) 参考DETR中的FFN设计让两个Head的卷积数量不同，回归Head包含4个卷积而分类Head则仅包含两个卷积；(2) 作者参考AutoAssign在回归Head上对每个锚点添加了一个隐式目标预测。</li>
<li>Other Detail。正如前面所提到的YOLOF中的预定义锚点是稀疏的，这会导致目标框与锚点之间的匹配质量下降。作者在图像上添加了一个随机移动操作以缓解该问题，同时作者发现这种移动对于最终的分类是有帮助的。</li>
</ul>
<h2 id="总结：-1"><a href="#总结：-1" class="headerlink" title="总结："></a>总结：</h2><h3 id="创新点："><a href="#创新点：" class="headerlink" title="创新点："></a>创新点：</h3><ul>
<li>FPN的关键在于针对稠密目标检测优化问题的“分而治之”解决思路，而非多尺度特征融合</li>
<li>提出了一种简单而有效的无FPN的baseline模型YOLOF，其包含两个关键成分<ul>
<li>Dilated Encoder：用于增加感受野，覆盖所有的目标尺度。</li>
<li>Uniform Matching ：解决Positive Anchor的不平衡问题。</li>
</ul>
</li>
</ul>
<h1 id="4-Transformer-Interpretability-Beyond-Attention-Visualization"><a href="#4-Transformer-Interpretability-Beyond-Attention-Visualization" class="headerlink" title="4. Transformer Interpretability Beyond Attention Visualization"></a>4. Transformer Interpretability Beyond Attention Visualization</h1><h2 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h2><p>自注意力机制，特别是Transformer逐渐成为文本处理领域的主流，并且在CV领域流行起来。为了可视化图像中有助于分类的部分，现有方法依赖于所获取到的注意力图，或者沿着注意力图进行启发式传播。本文提出了一种新的方法来为Transformer计算相关性。该方法基于深度泰勒分解规则分配局部相关性，之后传播这些相关性。该传播包含注意力层和跳跃连接。作者的解决方案基于一个特定的公式，该公式显示了跨层保持总体相关性。</p>
<p>Transformer网络的主要构成是自注意力层，其在两个tokens之间分配一个成对的注意力值。</p>
<h4 id="本文提出的可视化方法："><a href="#本文提出的可视化方法：" class="headerlink" title="本文提出的可视化方法："></a>本文提出的可视化方法：</h4><p><img src="https://i.loli.net/2021/03/26/fg6OuBk9csyiUAh.png" srcset="/img/loading.gif" alt="image-20210326093924093" style="zoom: 67%;" /></p>
<h2 id="总结：-2"><a href="#总结：-2" class="headerlink" title="总结："></a>总结：</h2><ul>
<li>本文提出了一种基于Transformer的方法将有助于分类的部分进行可视化。</li>
<li>其效果相对之前的方法有很大提高，并且是开源的，可以考虑将该方法用于VID。</li>
</ul>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Transformer/">Transformer</a>
                    
                      <a class="hover-with-bg" href="/tags/EBFA/">EBFA</a>
                    
                      <a class="hover-with-bg" href="/tags/YOLOF/">YOLOF</a>
                    
                      <a class="hover-with-bg" href="/tags/Transformer-Interpretability/">Transformer Interpretability</a>
                    
                  </div>
                
              </div>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2021/03/29/%E5%9B%BE%E5%83%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">图像目标检测简单综述</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2021/03/19/3-19/">
                        <span class="hidden-mobile">阅读笔记（3.19)</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    function loadValine() {
      addScript('https://cdn.staticfile.org/valine/1.4.14/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "bnCEF7PLYkERuDi9gYGIAK1q-gzGzoHsz",
          app_key: "ohFc9mmlCQxYi22T4AMQA2JY",
          placeholder: "说点什么吧~（请在上方填写您的昵称，昵称将显示在你的评论上）",
          path: window.location.pathname,
          avatar: "identicon",
          meta: ["nick","mail","link"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: false,
          recordIP: true,
          serverURLs: "",
        });
      });
    }
    createObserver(loadValine, 'vcomments');
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">

    
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>



    <div>
      <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
      <script>
          var now = new Date();
          function createtime() {
              var grt= new Date("06/22/2020 00:00:00");
              now.setTime(now.getTime()+250);
              days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
              hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
              if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
              mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
              seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
              snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
              document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
              document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
          }
          setInterval("createtime()",250);
      </script>
    </div>


    <div>
      <span id="Copyright">载入版权...</span>
      <script>
          var now = new Date();
          function createtime2() {
              var year = now.getFullYear();
              document.getElementById("Copyright").innerHTML = "Copyright © "+year+" htx's Blog, All rights reserved.";
          }
          setInterval("createtime2()",250);
      </script>
    </div>


    
  <!-- 备案信息 -->
  <div class="beian">
    <a href="http://beian.miit.gov.cn/" target="_blank"
       rel="nofollow noopener">豫ICP备2020026254号</a>
    
  </div>


    

  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "阅读笔记（3.26)&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>







  
  
    <script type="text/javascript">
      //定义获取词语下标
      var a_idx = 0;
      jQuery(document).ready(function ($) {
        //点击body时触发事件
        $("body").click(function (e) {
          //需要显示的词语
          var a = new Array("富强", "民主", "文明", "和谐", "自由", "平等", "公正", "法治", "爱国", "敬业", "诚信", "友善");
          //设置词语给span标签
          var $i = $("<span/>").text(a[a_idx]);
          //下标等于原来下标+1  余 词语总数
          a_idx = (a_idx + 1) % a.length;
          //获取鼠标指针的位置，分别相对于文档的左和右边缘。
          //获取x和y的指针坐标
          var x = e.pageX, y = e.pageY;
          //在鼠标的指针的位置给$i定义的span标签添加css样式
          $i.css({
            "z-index": 999,
            "top": y - 20,
            "left": x,
            "position": "absolute",
            "font-weight": "bold",
            "color": rand_color()
          });
          // 随机颜色
          function rand_color() {
            return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
          }
          //在body添加这个标签
          $("body").append($i);
          //animate() 方法执行 CSS 属性集的自定义动画。
          //该方法通过CSS样式将元素从一个状态改变为另一个状态。CSS属性值是逐渐改变的，这样就可以创建动画效果。
          //详情请看http://www.w3school.com.cn/jquery/effect_animate.asp
          $i.animate({
            //将原来的位置向上移动180
            "top": y - 180,
            "opacity": 0
            //1500动画的速度
          }, 1500, function () {
            //时间到了自动删除
            $i.remove();
          });
        });
      })
      ;
    </script>
  











  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?2f3f98d16f957573ec883289e3293112";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  

  





<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
</body>
</html>
